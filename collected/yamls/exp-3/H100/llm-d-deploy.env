export LLMDBENCH_CLUSTER_URL="https://api.pokprod001.ete14.res.ibm.com"
export LLMDBENCH_CLUSTER_NAMESPACE="llmdbench"
export LLMDBENCH_VLLM_PVC_NAME="model-cache"
export LLMDBENCH_VLLM_CPU_MEM="100Gi"
export LLMDBENCH_VLLM_LMCACHE_MAX_LOCAL_CPU_SIZE=80
export LLMDBENCH_VLLM_CPU_NR=8
export LLMDBENCH_VLLM_REPLICAS=2
export LLMDBENCH_VLLM_MAX_MODEL_LEN=10000
export LLMDBENCH_ENVIRONMENT_TYPES=p2p

# Endpoint Picker Parameters
export LLMDBENCH_EPP_ENABLE_PREFIX_AWARE_SCORER=true
export LLMDBENCH_EPP_PREFIX_AWARE_SCORER_WEIGHT=2.0
export LLMDBENCH_EPP_ENABLE_KVCACHE_AWARE_SCORER=false
export LLMDBENCH_EPP_ENABLE_LOAD_AWARE_SCORER=true
export LLMDBENCH_EPP_LOAD_AWARE_SCORER_WEIGHT=1.0

# Accelerator type
export LLMDBENCH_GPU_MODEL=NVIDIA-H100-80GB-HBM3

# Image version
export LLMDBENCH_VLLM_P2P_IMAGE_REPOSITORY=quay.io/llm-d/llm-d-dev
export LLMDBENCH_VLLM_P2P_IMAGE_TAG=lmcache-0.0.6-amd64
export LLMDBENCH_EPP_IMAGE=quay.io/llm-d/llm-d-gateway-api-inference-extension-dev:0.0.5-amd64
